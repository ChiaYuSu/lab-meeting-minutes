###### tags: `III`、`NTUST`
<details>
<summary>Outline</summary>

- [Lab Meeting -- 2020.08.10](#lab-meeting----20200810)
- [論文](#論文)
  - [題目](#題目)
  - [論文大綱](#論文大綱)
  - [摘要](#摘要)
  - [建議的方法](#建議的方法)
  - [性能評估](#性能評估)
    - [A. 分類器的性能評估](#a-分類器的性能評估)
    - [B. 特徵的性能評估](#b-特徵的性能評估)
    - [C. 未知用戶預測](#c-未知用戶預測)
  - [結論](#結論)
  - [參考文獻](#參考文獻)
  - [所有資料存放處](#所有資料存放處)
</details>

# Lab Meeting -- 2020.08.10
- 時　間：2020/8/10（一）
- 主持人：馬奕葳 教授
- 主　題：資策會開會

# 論文
## 題目
- 英文題目：[Towards Detecting Fake User Accounts in Facebook](https://drive.google.com/file/d/1qpzYTkOcc33jmFhbOmMmvjhyFSwBym7Z/view?usp=sharing)
- 中文題目：檢測 Facebook 中的虛假用戶的方法

## 論文大綱
<img src="1090810\1090810.003.jpeg" width="550px" />

1. [摘要（Abstract）](https://github.com/ChiaYuSu/lab-meeting-minutes/blob/master/1090810.md#摘要)
2. 介紹（Introduction）
3. 研究現狀（Related Work）
4. [建議的方法（Proposed Approach）](https://github.com/ChiaYuSu/lab-meeting-minutes/blob/master/1090810.md#建議的方法)
5. [性能評估（Evaluation）](https://github.com/ChiaYuSu/lab-meeting-minutes/blob/master/1090810.md#性能評估)
6. [結論（Conclusion）](https://github.com/ChiaYuSu/lab-meeting-minutes/blob/master/1090810.md#結論)
7. 未解決的問題和未來的工作（Open Issues And Future Work）

## 摘要
<img src="1090810\1090810.005.jpeg" width="550px" />

簡單帶過一下摘要，這篇論文提出了三個貢獻：
1. 收集了與 Facebook 上真實用戶和虛假用戶相關的數據。因為 Facebook 越來越嚴格的隱私設置還有不斷發展的 API (每個版本都增加了更多限制)，收集用戶數據越來越困難，所以這篇論文是靠人工的方式去蒐集要的 training 跟 test 的資料集。
2. 利用 Facebook 上的用戶反饋訊息來了解用戶個人資料活動，並確定 17 種特徵；使用這些特徵，並從總共 12 種不同種類的分類器中找出在檢測任務中表現出色的分類器。
3. 找出剛剛提到的 17 種特徵中哪些特徵集在假冒用戶檢測中貢獻最大。
   1. Comment
   2. Tag


## 建議的方法
<img src="1090810\1090810.007.jpeg" width="550px" />

剛剛有講到，因為 Facebook 越來越嚴格的隱私設置，所以本論文是採用人工的方式來搜集這些用戶數據，論文中一共搜集了 4,708 筆資料。
  | 用戶         | 用戶來源         |  筆數 |
  | ------------ | ---------------- | ----: |
  | 真實用戶     | 自己的朋友       |   549 |
  | 虛假用戶     | 垃圾郵件發送者   |   230 |
  | 假定真實用戶 | 自己的朋友的朋友 | 2,672 |
  | 假定虛假用戶 | 黑市用戶         | 1,257 |
  | 總共         |                  | 4,708 |

---
<img src="1090810\1090810.008.jpeg" width="550px" />

在收集了各種數據屬性之後，下一步就是識別和定義一套從這些數據屬性中衍生出來的特徵，這將有助於盡可能地區分真實用戶和虛假用戶。

論文最終制定了一套分為 6 個類別、17 個特徵的特徵集。

特徵概述：
1. Average_PostLikes_Received
   - 用戶在自己的 Post 中收到的平均點讚數
   - 理由：假用戶應發佈垃圾訊息，這可能有很低的點讚數
2. Average_Post_Liked
   - 用戶在別人的 Post 中平均點讚數
   - 理由：假用戶的活躍度通常要比普通用戶高
3. Average_PostComments_Received
   - 用戶在自己的 Post 收到的平均評論數
   - 理由：假帳戶應發佈垃圾訊息，這些訊息很可能只有很少的評論
4. Average_Post_Comments
   - 用戶在自己的 Post 平均評論數
   - 理由：假帳戶應發佈垃圾訊息，這些訊息可能採取大量評論的形式
5. Average_Tags
   - 用戶在自己的 Post 中使用 Tag 的平均數量
   - 理由：真實用戶應更頻繁地使用 Tag
6. Average_UserTags
   - 用戶在自己的 Post 中使用 Tag 別人的平均數量
   - 理由：真實用戶應更頻繁地使用 Tag
7. Average_UserTagged
   - 用戶在別人的 Post 中被人 Tag 的平均數量
   - 理由：真實用戶擁有真正的朋友，因此將被其朋友標記。虛假用戶未與其真實朋友關聯，因此不太可能被朋友標記
8. Average_PageTags
   - 用戶在自己的 Post 中使用 Tag 粉絲專頁的平均數量
   - 理由：虛假賬戶可能會標記更多頁面以使這個假帳號宣傳出去
9. Average_PostComment_UserTags
   - 用戶在自己的 Post 中的留言處 Tag 別人的平均數量
   - 理由：真實用戶比虛假用戶更常使用此功能
10. Average_PostCommentPageTags
   - 用戶在其他人的 Post 中 Tag 某一頁面的平均數量
   - 理由：虛假用戶通常比真實用戶更頻繁這樣做
11. Average_PostComment_Tagged
   - 用戶被其他人 Tag 的平均評論數，剛剛上面有一個 Average_UserTagged 這兩個是不一樣的，一個是考慮在 Post 中被 Tag 的平均數量，這一個是在 Comment 中被 Tag 的平均數量
   - 理由：理由跟剛剛的 Average_UserTagged 是一樣的。真實用戶擁有真正的朋友，因此將被其朋友標記。虛假用戶未與其真實朋友關聯，因此不太可能被朋友標記
12. Average_PagePost_Shared
   - 用戶每天分享的粉絲專頁的 Post 的平均數量
   - 理由：虛假的帳戶有可能會分享垃圾訊息，所以共享數可能會比普通用戶高很多
13. Average_Post_Shares
   - 用戶在自己的 Post 中被分享的平均數量
   - 理由：虛假用戶分享垃圾訊息，所以通常來說不太會被分享，那真實用戶分享是一般的訊息，所以通常來說比較容易被分享出去
14. Average_Wall_Posts_Received
   - 用戶每天在其他用戶的用戶牆上的貼文數
   - 理由：真實用戶擁有真實的朋友，因此，他們更有可能被朋友收到其牆上的牆貼，而假帳戶未與真實朋友鏈接，因此不太可能收到牆貼
15. Frac_Wall_Posts_Received_Liked
   - 某用戶喜歡的其他用戶在他的用戶的牆上貼文所佔的比例
   - 理由：虛假用戶不是真實用戶，很可能由機器人控制，這會導致該帳戶的用戶不喜歡虛假帳戶牆上的牆貼
16. Frac_Wall_Post_Received_Cmtd
   - A 用戶在 B 用戶留言，被 B 用戶回應的次數
   - 理由：虛假用戶不是真實用戶，很可能由機器人控制，這會導致假帳戶牆上的 Post 沒有該帳戶用戶發表評論的可能性更高
17. Average_Apps_Used
   - 用戶每天使用的平均應用數量
   - 理由：虛假用戶比較不會去使用這些應用程式

---
<img src="1090810\1090810.009.jpeg" width="550px" />

作為我們在 Facebook 上檢測偽造用戶的方法的最後一步，我們使用了 12 種不同的學習分類器，去看哪一個分類器最後的 accuracy 會最高。

## 性能評估
<img src="1090810\1090810.011.jpeg" width="550px" />

我們評估了各種機器學習分類模型對未知用戶用戶進行預測的能力，執行兩種類型的交叉驗證：
- holdout method
- 10-fold cross validation

---
### A. 分類器的性能評估
<img src="1090810\1090810.012.jpeg" width="550px" />

評估的目的是了解 12 個學習分類器中哪個分類表現最好。

在每個學習分類器的每個實驗中，對 777 個用戶用戶 (包括 548 個真實用戶和 229 個屬於垃圾郵件用戶集的假用戶) 的數據集進行了 10 倍交叉驗證，並且使用了包括 17 個特徵。 

結果是使用常見分類器可以實現接近 80％ 的分類器準確度。

---
<img src="1090810\1090810.013.jpeg" width="550px" />

看結果之前，先看一下這個混肴先看一下這個混淆矩陣，可以方便等一下的理解，左邊的 P, N 代表的是實際情況、上面的 P, N 代表的是猜測情況，所以組合起來就有四種結果：
- TP: 實際真用戶、猜測真用戶 -> 判斷正確
- TN: 實際假用戶、猜測假用戶 -> 判斷正確
- FP: 實際假用戶、猜測真用戶 -> 判斷錯誤
- FN: 實際真用戶、判斷假用戶 -> 判斷錯誤

所以等一下後面的結果，其實我們希望不管是針對真用戶或假用戶在判斷的過程都是正確的，所以從量化的數據來說，我們希望 TP, TN 值越高越好、FP, FN 值越低越好

---
<img src="1090810\1090810.014.jpeg" width="550px" />

上圖僅描繪了那些在分類器 Accuracy 達到 75％ 以上且 Error Rate 在 25％ 或更低的情況下表現相對較好的學習分類器。
1. Decision Tree (J48, C50, REPT, Random Tree, Random Forest) 和 Decision Rule Based (OneR, RIPPER, JRip) 分類器表現良好。也就是說，除單純貝氏分類器 (Naïve Bayes) 外，其他 7 個分類器的結果均具有 75-80％ 的 Accuracy 和 20-25％ 的 Error Rate。
2. 單純貝氏分類器 (Naïve Bayes) 的 Accuracy 最低，為 58％，但可以檢測到 92％ 的 TP Rate，這是所有分類器中最高的。
3. 除 OneR 之外，其他分類器均能夠檢測到 62-73％ 的 TP Rate。

---
### B. 特徵的性能評估
<img src="1090810\1090810.015.jpeg" width="550px" />

在這次評估中，論文中還根據 Facebook 的活動類型，將整個特徵集分為不同的類別。

我們的目的是確定每一類特徵，區分虛假用戶和真實用戶的能力。

我們在前面使用的同一數據集上進行了 10 倍的交叉驗證。雖然對所有的學習分類器都進行了評估，但本論文只描繪了兩個分類器 (J48, Random Forest)，因為剛剛在尋找最佳 Classification 時候發現除 Naïve Bayes 之外其他分類器的結果相似。

---
<img src="1090810\1090810.016.jpeg" width="550px" />

觀察結果是：
1. 所有分類器對所有特徵集的 Accuracy 均達到 70％ 以上，Error Rate 30％ 以下。
2. Comment 特徵和 Like 特徵成功檢測到真實個人資料，Comment 特徵的 TP Rate 為 60％ 以上，Like 特徵的 TP Rate 為 50％ 以上。
3. Tag, Share, WallPost and Apps 等特徵在檢測虛假用戶方面表現出良好的性能，TN Rate 為 95％ 以上。但這些特徵無法檢測到真實用戶的個人資料 (TP Rate 5％ 以下)，這可能是由於我們的數據集中真實用戶 (friends) 進行此類活動不足。

---
<img src="1090810\1090810.017.jpeg" width="550px" />

觀察結果是：
1. 儘管與 Like 和 Comment 特徵的檢測分類器 Accuracy 為 70％，Error Rate 在 30％ 以下，與其他分類器的結果相似，但對於其他特徵集，分類器 Accuracy 為 50％ 以下且 Error Rate 高達 50％ 以上。
2. Like 和 Comment 特徵的 TP Rate 非常低 (低於10％)，而與 Tag, Share, WallPost and Apps 特徵的 TP Rate 則高達 95％ 以上。相反，Like 和 Comment 特徵的 TN Rate 為 95％ 或更高，其餘特徵的 TN Rate 為 30％ 或更低。
3. 與 Like 和 Comment 特徵導致 FP Rate 為 5％ 以下，而 FN Rate 為 90％ 以上。另一方面，對於其餘特徵，FP Rate 和 FN Rate 分別為 70-85％ 和 0-6％。

---
### C. 未知用戶預測
<img src="1090810\1090810.018.jpeg" width="550px" />

接下來，是將測試集放進分類器中，看看哪個分類器準確度比較高
- 此實驗的訓練集包括 777 個用戶，548 個真實用戶和 229 個虛假用戶。
- 此實驗的測試集包括 3929 個用戶，2672 個假定的真實用戶和 1257 個假定的虛假用戶。 

實驗的目的是為測試集中的用戶預測標籤 (真實、偽造)，並在假設的基礎上對其進行標籤並分析結果。

---
<img src="1090810\1090810.019.jpeg" width="550px" />

此處的主要觀察結果是，除 Naïve Bayes 之外，所有分類器的檢測準確度均為 60％，錯誤率為 40％。

## 結論
<img src="1090810\1090810.021.jpeg" width="550px" />

1. 找到最好的分類器 (Random Forest)，準確率可達 79%，加入測試集後，準確率可達 60%。
2. Like and Comment 有助於最大程度的檢測虛假用戶。
3. 許多虛假用戶被歸類為真實用戶，這可能是由於虛假用戶模仿真實用戶行為以逃避檢測機制所致。

## 參考文獻
1. 待補

## 所有資料存放處
- [Paper presentation / 1090810](https://drive.google.com/drive/folders/1xrE2dz46Wwb7-XfbYvvFhj2-EH-8kvSt?usp=sharing)
- [Keynote](https://drive.google.com/file/d/1a-TYE6u6JuU4XQ_kDEPdp4gse4poVRBr/view?usp=sharing)
- [Keynote to PDF](https://drive.google.com/file/d/1qOs5oywsIfiwmNvoxU3wLX54lDT1kupk/view?usp=sharing)