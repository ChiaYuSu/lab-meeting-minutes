###### tags: `III`、`NTUST`
<details>
<summary>Outline</summary>

- [Lab Meeting -- 2020.08.03](#lab-meeting----20200803)
- [論文](#論文)
  - [題目](#題目)
  - [論文大綱](#論文大綱)
  - [摘要](#摘要)
  - [介紹](#介紹)
  - [研究現狀](#研究現狀)
  - [建議的方法和模型](#建議的方法和模型)
  - [實驗](#實驗)
  - [結論](#結論)
  - [參考文獻](#參考文獻)
  - [所有資料存放處](#所有資料存放處)
</details>

# Lab Meeting -- 2020.08.03
- 時　間：2020/8/3（一）
- 主持人：馬奕葳 教授
- 主　題：資策會開會

# 論文
## 題目
- 英文題目：[Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques]()
- 中文題目：使用 N-Gram 和機器學習技術檢測虛假新聞

## 論文大綱
<img src="1090803\1090803.003.jpeg" width="550px" />

1. [摘要（Abstract）]()
2. [介紹（Introduction）]()
3. [研究現狀（Related Works）]()
4. [建議的方法和模型（Proposed Approach and Models）]()
5. [實驗（Experiments）]()
6. [結論（Conclusion）]()

## 摘要
<img src="1090803\1090803.005.jpeg" width="550px" />

假新聞是一種現象，對我們的社會生活，特別是在政治世界中，具有重大影響。 虛假新聞檢測是一個新興的研究領域，正在受到關注，但由於可用資源 (即數據集、出版的文獻) 數量有限，因此涉及一些挑戰。

我們在本文中提出了一種使用 n-gram 分析和機器學習技術的假新聞檢測模型。我們研究並比較了兩種不同的特徵提取技術和六種不同的機器分類技術。實驗評估使用術語頻率倒置文檔頻率 (TF-IDF) 作為特徵提取技術，並使用線性支持向量機 (LSVM) 作為分類器，以達到 92％ 的精度，從而獲得最佳性能。


## 介紹
<img src="1090803\1090803.007.jpeg" width="550px" />

近年來，網路內容會搖擺用戶的決定和意見、網路評論意見是網路商城購買者的主要訊息來源，可幫助他們深入了解他們計劃購買的產品。

最近很明顯，垃圾評論不僅存在於產品評論和客戶反饋中。實際上，虛假新聞和誤導性文章是垃圾評論的另一種形式。傳播假新聞或謠言的一些最大來源是社交媒體網站，例如 Google Plus, Facebook, Twitter 和其他社交媒體。

即使假新聞不是一個新問題，但由於人們傾向於相信誤導性信息以及對假內容傳播的缺乏控制，檢測假新聞被認為是一項複雜的任務。在過去的兩年中，假新聞越來越受到關注，尤其是自 2016 年美國大選以來，人類很難去發現到假新聞。

可以說，一個人手動識別虛假新聞的唯一方法是對所涉及的主題有廣泛的了解。即使掌握了這些知識，也很難成功識別文章中的信息是真實的還是虛假的。網路和社交媒體的開放性以及計算機科學的最新進展，簡化了創建和傳播假新聞的過程。儘管更容易理解和追踪虛假評論的意圖和影響，但通過傳播虛假新聞進行宣傳的意圖和影響卻難以衡量或理解。

網路安全公司趨勢科技分析了全球數百家虛假新聞服務提供商。他們報告說，檢測假新聞是一項複雜的任務，比檢測假產品評論要困難得多，因為假新聞評論使用社交媒體和口口相傳很容易傳播。

本論文介紹了一種基於 n-gram 特徵的方法來檢測假新聞，該方法包括使用基於 n-gram 特徵的文字分析和機器學習分類技術。我們研究並比較了六種不同的監督分類技術，即 K-近鄰演算法 (KNN)、支持向量機 (SVM)、邏輯回歸 (LR)、線性支持向量機 (LSVM)、決策樹 (DT) 和隨機梯度下降 (SGD)。實驗評估是使用從真實和虛假新聞網站收集的數據集進行的，最終產生了不錯的結果。


## 研究現狀
<img src="1090803\1090803.009.jpeg" width="550px" />

假新聞檢測的研究仍處於早期階段，因為這是一個相對較新的現象，至少在社會關注的方面。我們在下面回顧一些已發表的工作。通常，**假新聞可以分為三類**：
- 第一類：假新聞，是完全由文章作者組成的完全假的新聞。
- 第二類：假諷刺新聞，這是假新聞，其主要目的是向讀者提供幽默。
- 第三類：寫得不好的新聞文章，雖然有一定程度的真實新聞，但並不完全準確。
  - 例如：使用政治人物的名言來報導一個完全假的故事。通常，這類新聞目的在炒作某些內容或偏見。

---
<img src="1090803\1090803.010.jpeg" width="550px" />

**羅賓 (Rubin, V.L.) 等人**，討論**三種類型**的假新聞。每個代表不准確或欺騙性的報告。此外，作者權衡了各種假新聞，以及使用不同的文字分析和預測建模方法檢測假新聞的利弊。
1. 通常捏造的假新聞不會在主流媒體，會再像是 yellow press (黃色新聞) 或 tabloids (小報) 上發表的新聞，因此很難收集。
2. 大型騙局具有創造力和獨特性，經常出現在多個平台上。作者認為，可能需要文字分析以外的方法來檢測這種類型的假新聞。
3. 幽默的假新聞，他們的作家打算娛樂，嘲笑甚至荒謬。這組作者說，這種假新聞樣式的性質可能會對文字分類技術的有效性產生不利影響。

作者認為**自然語言處理 (NLP)** 和欺騙檢測的最新進展可能有助於發現欺騙性消息。但是，缺乏可用的預測模型語料庫是設計檢測假新聞的有效模型的重要限制因素。

---
<img src="1090803\1090803.011.jpeg" width="550px" />

**Horne B.D. (霍恩) 等人**，說明了區分虛假和誠實文章是多麽明顯。根據他們的觀察，**假新聞標題中停頓詞和名詞較少，而名詞和動詞較多**。他們提取了不同的特徵，並將其分為以下**三類**：
1. 複雜度特徵可計算文本的複雜度和可讀性。
2. 心理學特徵說明並衡量了認知過程和寫作背後的個人顧慮，例如情感詞和隨意詞的數量。
3. 文體特徵反映了作者的風格和文本的語法，例如動詞數量和名詞數量。

前述特徵用於構建 **SVM 分類模型**。作者使用由 BuzzFeed 和其他新聞網站的真實新聞組成的數據集，以及 Burfoot 和 Baldwin 的諷刺數據集來測試他們的模型。當他們將**真實新聞與諷刺文章 (幽默文章)** 進行比較時，他們的**準確率達到了 91％**。但是，相對於**真實新聞預測假新聞**時，**準確性降低到 71％**。

---
<img src="1090803\1090803.012.jpeg" width="550px" />

**Wang W.Y. 等人**，引入了一個新的數據集 LIAR，這是一個可用於自動偽新聞檢測的新數據集。LIAR 的資料集大小要比其他數據集大得多，**與其他數據集不同，該數據集不包含完整的文章**，它包含 12800 個來自 **politifact 的手動標記的簡短聲明**。


---
<img src="1090803\1090803.013.jpeg" width="550px" />

**羅賓 (Rubin, V.L.) 等人**，提出了一種識別諷刺和幽默新聞文章的模型。他們主要在**四個領域 (civics, science, business 以及所謂的 soft news (entertainment, gossip articles))** 中檢查並檢查了 360 篇諷刺新聞。他們提出了一種 **SVM 分類模型**，該模型主要基於對諷刺新聞的分析而開發的五個特徵：
- 荒謬 (Absurdity)
- 幽默 (Humor)
- 語法 (Grammar)
- 負面影響 (Negative Affect)
- 標點符號 (Punctuation)

僅使用荒謬性 (Absurdity)、語法 (Grammar) 和標點符號 (Punctuation) 這三種功能的組合即可達到 90％ 的最高精度。

## 建議的方法和模型
<img src="1090803\1090803.015.jpeg" width="550px" />

N-gram 建模是一種流行的**特徵識別和分析方法**，用於語言建模和自然語言處理領域。N-gram 是長度為 n 的連續項目序列，它可以是單詞，字節，音節或字符的序列。文本分類中最常用的 N-gram 模型是基於單詞和基於字符的 N-gram。

在這項工作中，**我們使用基於單詞的 N-gram 來表示文本的上下文**，並生成對文本進行分類的功能。這個想法是從訓練數據中生成各種 N-gram 頻率曲線集，以代表假新聞和真實新聞。我們使用了幾個基於單詞 N-gram 特徵，並研究了 N-gram 長度對不同分類算法準確性的影響。

---
<img src="1090803\1090803.016.jpeg" width="550px" />

在使用 N-gram 和基於向量的模型表示數據之前，需要對數據進行某些細化，例如**停用詞刪除，標記化，小寫大寫，句子分段和標點符號刪除**。這將通過刪除數據中存在的不相關信息來幫助我們減小實際數據的大小。

我們創建了一個通用處理功能，以刪除每個文檔的標點符號和非字母字符；然後我們降低了文件中的字母大小寫。另外，創建了一個基於 n-gram 語法詞的標記器，以基於 n 的長度對文本進行切片。

---
<img src="1090803\1090803.017.jpeg" width="550px" />

停用詞是不重要的語言，當在文本分類中用作功能時會產生噪音。這些是句子中常用的單詞，可幫助連接思想或幫助句子結構。冠詞、介詞和連詞以及某些代詞被視為停用詞，我們刪除了諸如投影片上面顯示的這些詞。這些單詞已從每個文檔中刪除，並且已處理的文檔已存儲並傳遞到下一步。

---
<img src="1090803\1090803.018.jpeg" width="550px" />

將數據標記化之後，下一步就是將標記轉換為標準形式。詞幹只是將單詞更改為其原始形式，並減少數據中單詞類型或類別的數量。例如，單詞 running，ran 和 runner 將被簡化為單詞 run。我們使用詞幹使分類更快，更有效。此外，我們使用 Porter 詞幹分析器，由於其準確性，它是最常用的詞幹提取算法。

---
<img src="1090803\1090803.019.jpeg" width="550px" />

文本分類的挑戰之一是從高維數據中學習。文檔中有大量的術語，單詞和短語，導致學習過程的計算負擔很大。此外，不相關和多餘的功能可能會損害分類器的準確性和性能。因此，最好執行特徵縮減以減小文本特徵尺寸並避免較大的特徵空間尺寸。在這項研究中，我們研究了**兩種不同的特徵選擇方法**，即**詞頻 (TF) 和逆向檔案頻率 (TF-IDF)**。 

---
<img src="1090803\1090803.020.jpeg" width="550px" />

例如，在一篇 100 字的文件中，被我們篩選出兩個重要名詞，分別為 “healthy”, “wealthy”，“healthy” 在該篇文件中出現 10 次，“wealthy” 出現 3 次，那 “healthy” 的 TF = 10 / 100，而 “wealthy” 的 TF = 3 / 100。

**TF 值愈高，其單詞愈重要**，因此，在本文檔中，“healthy” 比 “wealthy” 更為重要。

---
<img src="1090803\1090803.021.jpeg" width="550px" />

換個角度來看，假設 D 是「所有的文件總數」，t(i) 是該單詞在所有文件總數中出現的「文件數」。

例如，有一千萬個 pages，“healthy” 出現在 1,000 個網頁當中，而 “wealthy” 出現在 100,000 個網頁當中，那麼 “healthy” 的 IDF = log (10,000,000/1,000) = 4，而 “wealthy” 的 IDF = log (10,000,000/100,000) = 2。所以，“healthy” 出現的機會小，與出現機會很大的 “wealthy” 比較起來，便顯得非常重要。

---
<img src="1090803\1090803.022.jpeg" width="550px" />

最後，將 tf(i,j) * idf(i) 來進行計算 (舉例來說 “healthy” 這個詞)，以某一特定文件內的高單詞頻率，乘上該單詞在文件總數中的低文件頻率，便可以產生 TF-IDF 權重值，且 **TF-IDF 傾向於過濾掉常見的單詞，保留重要的單詞**，如此一來，“welthy” 便不重要了。

---
<img src="1090803\1090803.023.jpeg" width="550px" />

上圖是分類過程的示意圖。它從對數據集進行預處理開始，方法是從數據中刪除不必要的字符和單詞。提取 n-gram 語法特徵，並形成代表所涉及文件的特徵矩陣。分類過程的最後一步是訓練分類器。我們調查了不同的分類器，以預測文件的類別。

我們專門研究了六種不同的機器學習算法，即**隨機梯度下降 (SGD)、支持向量機 (SVM)、線性支持向量機 (LSVM)、K 近鄰演算法 (KNN)、邏輯迴歸 (LR) 和決策樹 (DT)**。 我們使用了 Python 自然語言工具包 (NLTK) 中這些分類器的實現。

## 實驗
<img src="1090803\1090803.025.jpeg" width="550px" />

我們研究了兩種不同的特徵提取方法 TF-IDF 和 TF，並將 n-gram 語法的大小從 n = 1 到 n = 4。我們還改變了特徵選定的數量，範圍從 1,000 到 50,000。

---
<img src="1090803\1090803.026.jpeg" width="550px" />

SVM (支持向量機) 準確性結果。

---
<img src="1090803\1090803.027.jpeg" width="550px" />

LSVM (線性支持向量機) 準確性結果。

---
<img src="1090803\1090803.028.jpeg" width="550px" />

KNN (K 近鄰演算法) 準確性結果。

---
<img src="1090803\1090803.029.jpeg" width="550px" />

DT (決策樹) 準確性結果。

---
<img src="1090803\1090803.030.jpeg" width="550px" />

SGD (隨機梯度下降) 準確性結果。

---
<img src="1090803\1090803.031.jpeg" width="550px" />

LR (邏輯迴歸) 準確性結果。

---
<img src="1090803\1090803.032.jpeg" width="550px" />

從我們的實驗中獲得的結果來看：
- 基於**線性的分類器 (LSVM, SGD and LR) 比非線性分類器獲得了更好的結果**。
  - 但是，非線性分類器也不會太差。 DT 的準確度達到 89％。
  - 使用 **LSVM 作為 model 可獲得最高的精度**。無論使用多少個特徵值，此分類器的性能都很好。
- 同樣，**隨著 n-gram 語法的增加，算法的準確性也會降低**。
- 此外，**TF-IDF 勝過 TF**。

---
<img src="1090803\1090803.033.jpeg" width="550px" />

我們通過在 Adali 和 Horne 的數據集上運行模型進行了額外的實驗，其中包括 BuzzFeed 和其他新聞網站的真實新聞，以及 Burfoot 和 Baldwin 的諷刺數據集的諷刺。在將假新聞與真實新聞進行分類時，**我們使用 n-gram 特徵和 LSVM 算法獲得了 87％ 的準確性，這比作者在同一數據集上獲得的 71％ 的準確性要好得多**。

## 結論
<img src="1090803\1090803.035.jpeg" width="550px" />

在本文中，我們通過不同特徵提取技術的觀點，使用 n-gram 分析提出了一種假新聞檢測模型。此外，我們研究了兩種不同的特徵提取技術和六種不同的機器學習技術。當**使用一元語法 (uni-gram) 特徵和 LSVM 分類器時，提出的模型實現了最高的準確性**，最高的準確度分數是 92％。

假新聞檢測是一個新興的研究領域，**幾乎沒有公共數據集**。我們在現有數據集上運行我們的模型，顯示我們的模型優於數據集作者發布的原始方法。在以後的工作中，我們將在完成當前研究階段後，在其他幾個公共可用的數據集上運行模型，例如在 Wang W.Y. 論文中提到的 LIAR 數據集。


## 參考文獻
1. n 元語法, Retrieved from: https://zh.wikipedia.org/wiki/N元語法
2. 停用詞, Retrieved from: https://zh.wikipedia.org/wiki/%E5%81%9C%E7%94%A8%E8%AF%8D
3. 12.9.4 Full-Text Stopwords, Retrieved from: https://dev.mysql.com/doc/refman/8.0/en/fulltext-stopwords.html
4. tf-idf, Retrieved from: https://zh.wikipedia.org/wiki/Tf-idf
5. 文字探勘之前處理與 TF-IDF 介紹, Retrieved from: http://www.cc.ntu.edu.tw/chinese/epaper/0031/20141220_3103.html

## 所有資料存放處
- [Paper presentation / 1090830]()
- [Keynote]()
- [Keynote to PDF]()